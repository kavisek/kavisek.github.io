{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Website Notebook Content\n",
    "### Find the Path to Specific File (First Match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T23:03:07.799503Z",
     "start_time": "2018-09-24T23:03:07.794433Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from numpy.random import randint\n",
    "from shutil import copyfile\n",
    "from tqdm import *\n",
    "\n",
    "\n",
    "\n",
    "# Find file paths\n",
    "def find_all_lists(list_of_files, path):\n",
    "    '''\n",
    "    Find the Paths to all the Files in a list within this list of filen names\n",
    "    \n",
    "    Parameteres:\n",
    "    -----------\n",
    "    list_of_paths (list of str): list of file names\n",
    "    paths (str): abosolute path to the Directory, that we will search\n",
    "    \n",
    "    Examples:\n",
    "    -----------\n",
    "    find_all_lists(list_of_files,'/Users/Kavi/Documents/DataScience')\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    result = []\n",
    "    for name in list_of_files:\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            if name in files:\n",
    "                result.append(os.path.join(root, name)) # os.path.join(root, name) is a string\n",
    "    return result\n",
    "\n",
    "def desc_text(string):\n",
    "    '''\n",
    "    Fixing TQDM descrition text lenght\n",
    "    '''\n",
    "    # Remove Path\n",
    "    string = re.sub(r'^(.*[\\\\\\/])', '' ,string)\n",
    "    \n",
    "    # Fix File String\n",
    "    target_length = 25\n",
    "    if len(string) >= target_length:\n",
    "        string = string[:target_length]\n",
    "    else:\n",
    "        additional_len = target_length - len(string)\n",
    "        string = string+(' ')*additional_len\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T15:08:13.931624Z",
     "start_time": "2018-07-24T15:08:13.929567Z"
    }
   },
   "source": [
    "### Remove all \"-meta\" and \".ipynb' from the Content Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T23:03:15.271685Z",
     "start_time": "2018-09-24T23:03:15.265064Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#Find all file names within the content folder\n",
    "files_for_deletion = []\n",
    "for file in os.listdir(\"/Users/Kavi/Documents/Blog/content/\"):\n",
    "    if file.endswith(\"-meta\"):\n",
    "        files_for_deletion.append(os.path.join(\"/Users/Kavi/Documents/Blog/content/\", file))\n",
    "    elif file.endswith(\".ipynb\"):\n",
    "        files_for_deletion.append(os.path.join(\"/Users/Kavi/Documents/Blog/content/\", file))\n",
    "\n",
    "# Delete all HTML files within the local contente folder\n",
    "with trange(0,len(files_for_deletion))as pbar:\n",
    "    for file in files_for_deletion:\n",
    "        pbar.set_description(\"Removing Content Files: %s\" % desc_text(file))\n",
    "        pbar.update(1)\n",
    "        os.remove(file)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and Copy Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T23:03:54.943970Z",
     "start_time": "2018-09-24T23:03:19.395152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying File: 18-03-08 Removing Outlier: 100%|██████████| 44/44 [00:21<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Open Notebook Text File\n",
    "with open('/Users/Kavi/Documents/Blog/notebooks.txt','r') as f:\n",
    "    list_of_files = f.read().splitlines()\n",
    "\n",
    "# locate the path to all the files in the notebook text file within the DataScience diretory\n",
    "source_files = find_all_lists(list_of_files,'/Users/Kavi/Documents/Science')\n",
    "source_files\n",
    "\n",
    "\n",
    "meta_files = []\n",
    "txt_files = []\n",
    "nb_files = []\n",
    "\n",
    "# Copy all found files path 3 times under each file type and place them in the content folder\n",
    "with trange(0,len(source_files))as pbar:\n",
    "    for filepaths in source_files:\n",
    "        pbar.set_description(\"Copying File: %s\" % desc_text(filepaths))\n",
    "        pbar.update(1)\n",
    "        filename = re.findall(r'([^\\/]+$)',filepaths)[0]\n",
    "        copyfile(filepaths, '/Users/Kavi/Documents/Blog/content/'+filename)\n",
    "        copyfile(filepaths, '/Users/Kavi/Documents/Blog/content/'+filename+'.txt')\n",
    "        nb_files.append('/Users/Kavi/Documents/Blog/content/'+filename)\n",
    "        meta_files.append('/Users/Kavi/Documents/Blog/content/'+filename+'-meta')\n",
    "        txt_files.append('/Users/Kavi/Documents/Blog/content/'+filename+'.txt')\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Meta Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T23:04:20.735888Z",
     "start_time": "2018-09-24T23:03:58.048119Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44 [00:00<?, ?it/s]\n",
      "Appending Meta-Tag: 18-09-23 Time Series Fore:   0%|          | 0/44 [00:00<?, ?it/s]\n",
      "Appending Meta-Tag: 18-09-21 XG Boost Classif:   5%|▍         | 2/44 [00:00<00:10,  3.82it/s]\n",
      "Appending Meta-Tag: 18-09-21 Connecting to Da:   7%|▋         | 3/44 [00:01<00:13,  2.94it/s]\n",
      "Appending Meta-Tag: 18-09-20 Hatch, Linestyle:   9%|▉         | 4/44 [00:01<00:15,  2.55it/s]\n",
      "Appending Meta-Tag: 18-09-19 Hierarchical Clu:  11%|█▏        | 5/44 [00:02<00:17,  2.29it/s]\n",
      "Appending Meta-Tag: 18-09-16 Sparse Matrix.ip:  14%|█▎        | 6/44 [00:02<00:17,  2.17it/s]\n",
      "Appending Meta-Tag: 18-09-16 Reweighting Clas:  16%|█▌        | 7/44 [00:03<00:17,  2.10it/s]\n",
      "Appending Meta-Tag: 18-09-16 Dummy Classifier:  18%|█▊        | 8/44 [00:03<00:17,  2.05it/s]\n",
      "Appending Meta-Tag: 18-09-15 Gradient Boostin:  20%|██        | 9/44 [00:04<00:17,  1.99it/s]\n",
      "Appending Meta-Tag: 18-09-14 Random Forest Cl:  23%|██▎       | 10/44 [00:04<00:17,  1.97it/s]\n",
      "Appending Meta-Tag: 18-09-13 Time Zone Conver:  25%|██▌       | 11/44 [00:05<00:16,  1.96it/s]\n",
      "Appending Meta-Tag: 18-09-12 PCA.ipynb-meta  :  27%|██▋       | 12/44 [00:05<00:16,  1.96it/s]\n",
      "Appending Meta-Tag: 18-09-10 Linear Regressio:  30%|██▉       | 13/44 [00:06<00:15,  1.95it/s]\n",
      "Appending Meta-Tag: 18-09-05 Dropping Feature:  32%|███▏      | 14/44 [00:06<00:15,  1.95it/s]\n",
      "Appending Meta-Tag: 18-09-03 Using TQDM.ipynb:  34%|███▍      | 15/44 [00:07<00:14,  1.95it/s]\n",
      "Appending Meta-Tag: 18-09-03 Isolation Forest:  36%|███▋      | 16/44 [00:07<00:14,  1.95it/s]\n",
      "Appending Meta-Tag: 18-09-01 Decision Tree Cl:  39%|███▊      | 17/44 [00:08<00:13,  1.95it/s]\n",
      "Appending Meta-Tag: 18-08-31 Confusion Matric:  41%|████      | 18/44 [00:08<00:13,  1.92it/s]\n",
      "Appending Meta-Tag: 18-08-02 Downsampling.ipy:  43%|████▎     | 19/44 [00:09<00:12,  1.93it/s]\n",
      "Appending Meta-Tag: 18-08-02 Import Matlab Da:  45%|████▌     | 20/44 [00:09<00:12,  1.94it/s]\n",
      "Appending Meta-Tag: 18-08-02 Crosstab Table.i:  48%|████▊     | 21/44 [00:10<00:11,  1.94it/s]\n",
      "Appending Meta-Tag: 18-08-01 DBSCAN.ipynb-met:  50%|█████     | 22/44 [00:10<00:11,  1.95it/s]\n",
      "Appending Meta-Tag: 18-08-01 Plotting Residua:  52%|█████▏    | 23/44 [00:11<00:10,  1.95it/s]\n",
      "Appending Meta-Tag: 18-08-01 Histograms.ipynb:  55%|█████▍    | 24/44 [00:11<00:10,  1.95it/s]\n",
      "Appending Meta-Tag: 18-08-01 Heatmaps.ipynb-m:  57%|█████▋    | 25/44 [00:12<00:09,  1.94it/s]\n",
      "Appending Meta-Tag: 18-08-01 Standardizations:  59%|█████▉    | 26/44 [00:12<00:09,  1.94it/s]\n",
      "Appending Meta-Tag: 18-08-01 Null Values.ipyn:  61%|██████▏   | 27/44 [00:13<00:08,  1.95it/s]\n",
      "Appending Meta-Tag: 18-08-01 K-Nearest Neighb:  64%|██████▎   | 28/44 [00:13<00:08,  1.94it/s]\n",
      "Appending Meta-Tag: 18-08-01 Cross Validation:  66%|██████▌   | 29/44 [00:14<00:07,  1.94it/s]\n",
      "Appending Meta-Tag: 18-08-01 Train-Test Split:  68%|██████▊   | 30/44 [00:14<00:07,  1.95it/s]\n",
      "Appending Meta-Tag: 18-08-01 Randomized Grid :  70%|███████   | 31/44 [00:15<00:06,  1.95it/s]\n",
      "Appending Meta-Tag: 18-08-01 Tools of a Data :  73%|███████▎  | 32/44 [00:16<00:06,  1.95it/s]\n",
      "Appending Meta-Tag: 18-07-31 Fizzbuzz.ipynb-m:  75%|███████▌  | 33/44 [00:16<00:05,  1.96it/s]\n",
      "Appending Meta-Tag: 18-07-31 Regex in Python.:  77%|███████▋  | 34/44 [00:17<00:05,  1.96it/s]\n",
      "Appending Meta-Tag: 18-07-24 Binning Features:  80%|███████▉  | 35/44 [00:17<00:04,  1.96it/s]\n",
      "Appending Meta-Tag: 18-07-24 Converting Noteb:  82%|████████▏ | 36/44 [00:18<00:04,  1.95it/s]\n",
      "Appending Meta-Tag: 18-07-24 Label Encoding.i:  84%|████████▍ | 37/44 [00:18<00:03,  1.95it/s]\n",
      "Appending Meta-Tag: 18-07-07 Styling DataFram:  86%|████████▋ | 38/44 [00:19<00:03,  1.95it/s]\n",
      "Appending Meta-Tag: 18-07-07 Resampling Datet:  89%|████████▊ | 39/44 [00:19<00:02,  1.95it/s]\n",
      "Appending Meta-Tag: 18-07-04 Select Dtypes.ip:  91%|█████████ | 40/44 [00:20<00:02,  1.95it/s]\n",
      "Appending Meta-Tag: 18-19-22 Files To and Fro:  93%|█████████▎| 41/44 [00:20<00:01,  1.95it/s]\n",
      "Appending Meta-Tag: 18-06-23 Using OS Module.:  95%|█████████▌| 42/44 [00:21<00:01,  1.95it/s]\n",
      "Appending Meta-Tag: 18-03-28 Creating Dummy V:  98%|█████████▊| 43/44 [00:21<00:00,  1.95it/s]\n",
      "Appending Meta-Tag: 18-03-08 Removing Outlier: 100%|██████████| 44/44 [00:22<00:00,  1.95it/s]\n",
      "44it [00:22,  1.94it/s]\u001b[A\n",
      "\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# For each text file in the directory, open its file and append HMTL meta tag information to the file\n",
    "\n",
    "\n",
    "with trange(0,len(meta_files))as pbar:\n",
    "    for nb_filepath, txt_filepath, meta_filepath in tqdm(zip(nb_files,txt_files,meta_files)):\n",
    "        # Update TQDM Bar\n",
    "        pbar.set_description(\"Appending Meta-Tag: %s\" % desc_text(meta_filepath))\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Open Text File and Read Information to Create Meta-file\n",
    "        with open(txt_filepath,'r',encoding='utf-8') as file: \n",
    "            f_read_lines = file.readlines()\n",
    "            \n",
    "        with open(txt_filepath,'r',encoding='utf-8') as file:\n",
    "            f_read = file.read()\n",
    "            \n",
    "            \n",
    "            title = re.findall(r'\"#(.*?)\\\\n\"', f_read)[0]\n",
    "            slug = re.findall(r'\"#(.*?)\\\\n\"', f_read)[0]\n",
    "            \n",
    "\n",
    "            # Locate Date Information\n",
    "            date = txt_filepath.strip('/Users/Kavi/Documents/Blog/content/')\n",
    "            date = re.findall(r'[0-9][0-9]-[0-9][0-9]-[0-9][0-9]',date,flags=0)\n",
    "            date = date[0]\n",
    "            year = date[0:2]\n",
    "            month = date[3:5]\n",
    "            month = month.lstrip('0')\n",
    "            day = date[6:8]\n",
    "            #day = day.lstrip('0')\n",
    "           \n",
    "            date = \"20\"+year+\"-\"+month+\"-\"+day+' 00:00'\n",
    "            \n",
    "\n",
    "            # Option Print Statements\n",
    "            # print(txt_filepath)\n",
    "            # print(meta_filepath)\n",
    "            # print(date)\n",
    "            # Append tag, title, category, date information to each file \n",
    "\n",
    "            # Assign Meta File Variables before insertion\n",
    "            modified_date = str(datetime.now().year)+\"-\"+str(datetime.now().month)+\"-\"+str(datetime.now().day)+' 00:00'\n",
    "            category = 'Novice'\n",
    "            tag = 'Python'\n",
    "            author ='Kavi Sekhon'\n",
    "            summary = re.findall(r'(?=<span>)(.*\\n?)(?=</span>)',f_read)[0][0:150].strip('<span>') + '..'\n",
    "\n",
    "        \n",
    "        # Write Metat-File\n",
    "        with open(meta_filepath,'w',encoding='utf-8') as f2: \n",
    "            \n",
    "            # Write Pelican Header in Meta File\n",
    "            f2.write(f'''Title:{title}\\nDate: {date}\\nCategory: {category}\\nTags: {tag}'''+\n",
    "                     f'''\\nSlug:{title}\\nAuthor: {author}\\nSummary: {summary}''')\n",
    "            \n",
    "            # Write Everything Except Notebook Header in Meta File\n",
    "            for line in f_read_lines:\n",
    "                if title not in line:\n",
    "                    f2.write(line)\n",
    "        \n",
    "        with open(nb_filepath,'w',encoding='utf-8') as f1:\n",
    "            for line in f_read_lines:\n",
    "                if title not in line:\n",
    "                    f1.write(line)\n",
    "        \n",
    "        # Sleep half-a second\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T23:04:51.198555Z",
     "start_time": "2018-09-24T23:04:28.885343Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing Content Text Files: 18-03-08 Removing Outlier: 100%|██████████| 44/44 [00:21<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove all the text files for the txt path\n",
    "with trange(0,len(meta_files))as pbar:\n",
    "    for txt_filepath in txt_files:\n",
    "        pbar.set_description(\"Removing Content Text Files: %s\" % desc_text(txt_filepath))\n",
    "        pbar.update(1)\n",
    "        os.remove(txt_filepath)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kavi Sekhon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
