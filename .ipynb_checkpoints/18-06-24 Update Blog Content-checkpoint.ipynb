{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Website Notebook Content\n",
    "### Find the Path to Specific File (First Match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T17:46:05.378400Z",
     "start_time": "2018-09-17T17:46:05.373976Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from numpy.random import randint\n",
    "from shutil import copyfile\n",
    "from tqdm import *\n",
    "\n",
    "\n",
    "\n",
    "# Find file paths\n",
    "def find_all_lists(list_of_files, path):\n",
    "    '''\n",
    "    Find the Paths to all the Files in a list within this list of filen names\n",
    "    \n",
    "    Parameteres:\n",
    "    -----------\n",
    "    list_of_paths (list of str): list of file names\n",
    "    paths (str): abosolute path to the Directory, that we will search\n",
    "    \n",
    "    Examples:\n",
    "    -----------\n",
    "    find_all_lists(list_of_files,'/Users/Kavi/Documents/DataScience')\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    result = []\n",
    "    for name in list_of_files:\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            if name in files:\n",
    "                result.append(os.path.join(root, name)) # os.path.join(root, name) is a string\n",
    "    return result\n",
    "\n",
    "def desc_text(string):\n",
    "    '''\n",
    "    Fixing TQDM descrition text lenght\n",
    "    '''\n",
    "    # Remove Path\n",
    "    string = re.sub(r'^(.*[\\\\\\/])', '' ,string)\n",
    "    \n",
    "    # Fix File String\n",
    "    target_length = 25\n",
    "    if len(string) >= target_length:\n",
    "        string = string[:target_length]\n",
    "    else:\n",
    "        additional_len = target_length - len(string)\n",
    "        string = string+(' ')*additional_len\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-24T15:08:13.931624Z",
     "start_time": "2018-07-24T15:08:13.929567Z"
    }
   },
   "source": [
    "### Remove all \"-meta\" and \".ipynb' from the Content Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T18:00:45.689067Z",
     "start_time": "2018-09-17T18:00:45.680616Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing Content Files: 18-09-21 Connecting to Da: 100%|██████████| 6/6 [00:02<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#Find all file names within the content folder\n",
    "files_for_deletion = []\n",
    "for file in os.listdir(\"/Users/Kavi/Documents/Blog/content/\"):\n",
    "    if file.endswith(\"-meta\"):\n",
    "        files_for_deletion.append(os.path.join(\"/Users/Kavi/Documents/Blog/content/\", file))\n",
    "    elif file.endswith(\".ipynb\"):\n",
    "        files_for_deletion.append(os.path.join(\"/Users/Kavi/Documents/Blog/content/\", file))\n",
    "\n",
    "# Delete all HTML files within the local contente folder\n",
    "with trange(0,len(files_for_deletion))as pbar:\n",
    "    for file in files_for_deletion:\n",
    "        pbar.set_description(\"Removing Content Files: %s\" % desc_text(file))\n",
    "        pbar.update(1)\n",
    "        os.remove(file)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and Copy Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/Kavi/Documents/Science/Predictive/18-09-21 XG Boost Classifier.ipynb', '/Users/Kavi/Documents/Science/Pipelines/18-09-21 Connecting to Databases.ipynb', '/Users/Kavi/Documents/Science/Visualizations/18-09-20 Hatch, Linestyle, Marker.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(source_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T18:01:53.109560Z",
     "start_time": "2018-09-17T18:01:16.628908Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying File: 18-09-20 Hatch, Linestyle: 100%|██████████| 3/3 [00:01<00:00,  3.02it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Open Notebook Text File\n",
    "with open('/Users/Kavi/Documents/Blog/notebooks.txt','r') as f:\n",
    "    list_of_files = f.read().splitlines()\n",
    "\n",
    "# locate the path to all the files in the notebook text file within the DataScience diretory\n",
    "source_files = find_all_lists(list_of_files,'/Users/Kavi/Documents/Science')\n",
    "source_files\n",
    "\n",
    "\n",
    "meta_files = []\n",
    "txt_files = []\n",
    "nb_files = []\n",
    "\n",
    "# Copy all found files path 3 times under each file type and place them in the content folder\n",
    "with trange(0,len(source_files))as pbar:\n",
    "    for filepaths in source_files:\n",
    "        pbar.set_description(\"Copying File: %s\" % desc_text(filepaths))\n",
    "        pbar.update(1)\n",
    "        filename = re.findall(r'([^\\/]+$)',filepaths)[0]\n",
    "        copyfile(filepaths, '/Users/Kavi/Documents/Blog/content/'+filename)\n",
    "        copyfile(filepaths, '/Users/Kavi/Documents/Blog/content/'+filename+'.txt')\n",
    "        nb_files.append('/Users/Kavi/Documents/Blog/content/'+filename)\n",
    "        meta_files.append('/Users/Kavi/Documents/Blog/content/'+filename+'-meta')\n",
    "        txt_files.append('/Users/Kavi/Documents/Blog/content/'+filename+'.txt')\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Meta Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-17T17:52:23.939456Z",
     "start_time": "2018-09-17T17:52:00.347901Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Appending Meta-Tag: 18-09-21 XG Boost Classif:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Appending Meta-Tag: 18-09-21 Connecting to Da:  67%|██████▋   | 2/3 [00:00<00:00,  3.84it/s]\n",
      "Appending Meta-Tag: 18-09-20 Hatch, Linestyle: 100%|██████████| 3/3 [00:01<00:00,  2.98it/s]\n",
      "3it [00:01,  1.91it/s]\u001b[A\n",
      "\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# For each text file in the directory, open its file and append HMTL meta tag information to the file\n",
    "\n",
    "\n",
    "with trange(0,len(meta_files))as pbar:\n",
    "    for nb_filepath, txt_filepath, meta_filepath in tqdm(zip(nb_files,txt_files,meta_files)):\n",
    "        # Update TQDM Bar\n",
    "        pbar.set_description(\"Appending Meta-Tag: %s\" % desc_text(meta_filepath))\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Open Text File and Read Information to Create Meta-file\n",
    "        with open(txt_filepath,'r',encoding='utf-8') as file: \n",
    "            f_read_lines = file.readlines()\n",
    "            \n",
    "        with open(txt_filepath,'r',encoding='utf-8') as file:\n",
    "            f_read = file.read()\n",
    "            \n",
    "            \n",
    "            title = re.findall(r'\"#(.*?)\\\\n\"', f_read)[0]\n",
    "            slug = re.findall(r'\"#(.*?)\\\\n\"', f_read)[0]\n",
    "            \n",
    "\n",
    "            # Locate Date Information\n",
    "            date = txt_filepath.strip('/Users/Kavi/Documents/Blog/content/')\n",
    "            date = re.findall(r'[0-9][0-9]-[0-9][0-9]-[0-9][0-9]',date,flags=0)\n",
    "            date = date[0]\n",
    "            year = date[0:2]\n",
    "            month = date[3:5]\n",
    "            month = month.lstrip('0')\n",
    "            day = date[6:8]\n",
    "            #day = day.lstrip('0')\n",
    "           \n",
    "            date = \"20\"+year+\"-\"+month+\"-\"+day+' 00:00'\n",
    "            \n",
    "\n",
    "            # Option Print Statements\n",
    "            # print(txt_filepath)\n",
    "            # print(meta_filepath)\n",
    "            # print(date)\n",
    "            # Append tag, title, category, date information to each file \n",
    "\n",
    "            # Assign Meta File Variables before insertion\n",
    "            modified_date = str(datetime.now().year)+\"-\"+str(datetime.now().month)+\"-\"+str(datetime.now().day)+' 00:00'\n",
    "            category = 'Novice'\n",
    "            tag = 'Python'\n",
    "            author ='Kavi Sekhon'\n",
    "            summary = re.findall(r'(?=<span>)(.*\\n?)(?=</span>)',f_read)[0][0:150].strip('<span>') + '..'\n",
    "\n",
    "        \n",
    "        # Write Metat-File\n",
    "        with open(meta_filepath,'w',encoding='utf-8') as f2: \n",
    "            \n",
    "            # Write Pelican Header in Meta File\n",
    "            f2.write(f'''Title:{title}\\nDate: {date}\\nCategory: {category}\\nTags: {tag}'''+\n",
    "                     f'''\\nSlug:{title}\\nAuthor: {author}\\nSummary: {summary}''')\n",
    "            \n",
    "            # Write Everything Except Notebook Header in Meta File\n",
    "            for line in f_read_lines:\n",
    "                if title not in line:\n",
    "                    f2.write(line)\n",
    "        \n",
    "        with open(nb_filepath,'w',encoding='utf-8') as f1:\n",
    "            for line in f_read_lines:\n",
    "                if title not in line:\n",
    "                    f2.write(line)\n",
    "        \n",
    "        # Sleep half-a second\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-17T18:01:58.947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing Content Text Files: 18-09-20 Hatch, Linestyle: 100%|██████████| 3/3 [00:01<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove all the text files for the txt path\n",
    "with trange(0,len(meta_files))as pbar:\n",
    "    for txt_filepath in txt_files:\n",
    "        pbar.set_description(\"Removing Content Text Files: %s\" % desc_text(txt_filepath))\n",
    "        pbar.update(1)\n",
    "        os.remove(txt_filepath)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kavi Sekhon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
