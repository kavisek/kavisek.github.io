{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the OS Module\n",
    "\n",
    "<span>This notebook is a combination of little snippets of Python code from Python's OS module that can I found useful for a variety of tasks. These tasks include removing files from directories, moving files from directories, parsing content from the notebook, appending content to files, changing file types, etc. Hopefully, you find some useful code below.</span>\n",
    "\n",
    "### Import Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:00.215954Z",
     "start_time": "2018-09-11T00:57:00.213909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import module\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Current Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:00.221439Z",
     "start_time": "2018-09-11T00:57:00.217766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kavi/Documents/DataScience/Pipelines'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current directory\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Path Function\n",
    "\n",
    "Search the given directory and it's subdirectories for the first instance a specific file. Return the file path of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:00.227354Z",
     "start_time": "2018-09-11T00:57:00.224008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the find path function\n",
    "def find_path(name, path):\n",
    "    '''\n",
    "    Search the given directory for the first instance a specific file. \n",
    "    Return the file path of this file.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    name: name of the file (str)\n",
    "    path: absolute path to the directory to search withing (str)\n",
    "\n",
    "    Example\n",
    "    --------\n",
    "    >>>> find_path('10-15-17 Rescaling Features.ipynb',\n",
    "          '/Users/Kavi/Documents/DataScience')\n",
    "    '''\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:00.244927Z",
     "start_time": "2018-09-11T00:57:00.229491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Kavi/Documents/DataScience/Guides/10-15-17 Rescaling Features.ipynb'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run our Find Path Punction\n",
    "find_path('10-15-17 Rescaling Features.ipynb',\n",
    "          '/Users/Kavi/Documents/DataScience')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Breaking Down the Find Path Function\n",
    "\n",
    "The `os.walk(path)` function is pretty cool. Let's take a moment to break down each variable this function returns the `root` variable is the directory we are searching, `dirs` are the recursive subdirectories that the function is searching, and `files` are the files that exist in the directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:00.250890Z",
     "start_time": "2018-09-11T00:57:00.246249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------\n",
      "Root: /Users/Kavi/Documents/DataScience\n",
      "\n",
      "\n",
      "---------------\n",
      "Dirs: ['Predictive Analysis', 'Kaggle', 'FlashCards', 'Whitepapers', 'DateTime', 'Articles', 'Other', 'Competitions', 'Descriptive Analysis', 'Pipelines', 'Books', 'Stack Overflow', 'Visualizations', 'Notes', 'Guides', 'Economics', 'Tutorials', '.git', 'Brainstation', 'Community', 'Interviews', 'Techniques', 'SQL']\n",
      "\n",
      "\n",
      "---------------\n",
      "Files: ['.DS_Store', 'Portfolio.md', 'README.md', '.gitignore']\n",
      "\n",
      "\n",
      "---------------\n",
      "<generator object walk at 0x1128d0e08>\n"
     ]
    }
   ],
   "source": [
    "# Breaking Down this Function\n",
    "path = '/Users/Kavi/Documents/DataScience'\n",
    "name = 'README.md'\n",
    "result = []\n",
    "\n",
    "# Print the root, diretories, and files in our path\n",
    "for root, dirs, files in os.walk(path):\n",
    "    print('\\n\\n'+'-'*15)\n",
    "    print('Root:',root)\n",
    "    print('\\n\\n'+'-'*15)\n",
    "    print('Dirs:',dirs)\n",
    "    print('\\n\\n'+'-'*15)\n",
    "    print('Files:',files)\n",
    "    print('\\n\\n'+'-'*15)\n",
    "    print(os.walk(path))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T20:29:24.653912Z",
     "start_time": "2018-07-23T16:29:24.651629-04:00"
    }
   },
   "source": [
    "\n",
    "### Find All Paths Function\n",
    "\n",
    "Search the given directory and it's subdirectory for the every instance of a specific file. Return the all file paths of this file as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:00.257377Z",
     "start_time": "2018-09-11T00:57:00.253274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the find all paths function\n",
    "def find_all_paths_one_file(name, path):\n",
    "    '''\n",
    "    Search the given directory and it's subdirectory for the every \n",
    "    instance of a specific file. Return the all file paths of this \n",
    "    file as a list.\n",
    "\n",
    "        Parameter\n",
    "    ---------\n",
    "    name: name of the file (str)\n",
    "    path: absolute path to the directory to search withing (str)\n",
    "\n",
    "    Example\n",
    "    --------\n",
    "    >>>> find_all_paths_one_file('README.md','/Users/Kavi/Documents/DataScience')\n",
    "\n",
    "    '''\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            # os.path.join(root, name) is a string\n",
    "            result.append(os.path.join(root, name))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:00.533701Z",
     "start_time": "2018-09-11T00:57:00.259417Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/Kavi/Documents/DataScience/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Predictive Analysis/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Competitions/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Competitions/DonorsChoose Application/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Descriptive Analysis/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Pipelines/AWS Pipelines/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Notes/Readings/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Tutorials/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Tutorials/Tutorial - Luigi/data-engineering-101-master/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Tutorials/Tutorial - Luigi/data-engineering-101-master/topmodel/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Brainstation/Other/WebDev Class Slack/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Community/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Techniques/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/SQL/README.md']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run our \"find all paths\" function\n",
    "find_all_paths_one_file('README.md','/Users/Kavi/Documents/DataScience')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Find All Path for a list of Files\n",
    "Search the given directory and it's subdirectory for the every instance of ever file in a list. Return the all file paths for every file as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:00.539169Z",
     "start_time": "2018-09-11T00:57:00.535381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the \"find_all_paths_multi_file\" function\n",
    "def find_all_paths_multil_files(list_of_files, path):\n",
    "    '''\n",
    "    Search the given directory and it's subdirectory for the every \n",
    "    instance of ever file in a list. Return the all file paths for \n",
    "    every file as a list.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    list_of_files: list of names for the files we are searching for (list)\n",
    "    path: absolute path to the directory to search withing (str)\n",
    "\n",
    "    Example\n",
    "    --------\n",
    "    >>>> find_all_paths_one_file('README.md','/Users/Kavi/Documents/DataScience')\n",
    "    \n",
    "    '''\n",
    "    result = []\n",
    "    for name in list_of_files:\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            if name in files:\n",
    "                # os.path.join(root, name) is a string\n",
    "                result.append(os.path.join(root, name))\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:01.066302Z",
     "start_time": "2018-09-11T00:57:00.541289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/Kavi/Documents/DataScience/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Predictive Analysis/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Competitions/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Competitions/DonorsChoose Application/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Descriptive Analysis/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Pipelines/AWS Pipelines/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Notes/Readings/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Tutorials/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Tutorials/Tutorial - Luigi/data-engineering-101-master/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Tutorials/Tutorial - Luigi/data-engineering-101-master/topmodel/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Brainstation/Other/WebDev Class Slack/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Community/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Techniques/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/SQL/README.md',\n",
       " '/Users/Kavi/Documents/DataScience/Tutorials/Tutorial - Pandas/02-01-17 4 Time Saving Tricks in Pandas.ipynb']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a list of files we all looking for\n",
    "list_of_files = ['README.md',\n",
    "                 '02-01-17 4 Time Saving Tricks in Pandas.ipynb']\n",
    "\n",
    "# Run our \"find_all_paths_all_files\" function\n",
    "find_all_paths_all_files(list_of_files,'/Users/Kavi/Documents/DataScience')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Importing Data From Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:01.072998Z",
     "start_time": "2018-09-11T00:57:01.068065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18-09-15 Model Stacking.ipynb\\n18-09-10 Linear Regression.ipynb\\n18-09-05 Dropping Features.ipynb\\n18-09-03 Using TQDM.ipynb\\n18-09-03 Isolation Forest Classifier.ipynb\\n18-08-31 Confusion Matrices.ipynb\\n18-08-02 Downsampling.ipynb\\n18-08-02 Import Matlab Data.ipynb\\n18-08-01 Plotting Residuals.ipynb\\n18-08-01 Histograms.ipynb\\n18-08-01 Dimensional Pivot Table.ipynb\\n18-08-01 Heatmaps.ipynb\\n18-08-01 Standardizations.ipynb\\n18-08-01 Handling Missing Data.ipynb\\n18-08-01 K-Nearest Neighbours Classifier.ipynb\\n18-08-01 Random Forest Classifier.ipynb\\n18-08-01 Decision Tree Classifier.ipynb\\n18-08-01 Cross Validation and K-Folds.ipynb\\n18-08-01 Train-Test Split.ipynb\\n18-08-01 Recursive Feature Elimination.ipynb\\n18-08-01 Random Grid Search.ipynb\\n18-08-01 Full Grid Search.ipynb\\n18-08-01 DBSCAN.ipynb\\n18-08-01 Tools of a Data Scientist.ipynb\\n18-07-31 Fizzbuzz.ipynb\\n18-07-31 Regex in Python.ipynb\\n18-07-31 Logistic Regression.ipynb\\n18-07-29 Iris Analysis.ipynb\\n18-07-29 Classification Models.ipynb\\n18-07-28 Notebook Snippets.ipynb\\n18-07-24 Binning Features.ipynb\\n18-07-24 Converting Notebook to Slides.ipynb\\n18-07-24 Label Encoding.ipynb\\n18-07-07 Styling DataFrames.ipynb\\n18-07-07 Resampling Datetime.ipynb\\n18-07-04 Select Dtypes.ipynb\\n18-07-03 Writing a File to AWS S3.ipynb\\n18-07-03 Reading a File from AWS S3.ipynb\\n18-07-03 Connecting to a Local Database.ipynb\\n18-07-03 Connecting to a Local Database with SHH.ipynb\\n18-06-23 Using OS Module.ipynb\\n18-06-06 Every Matplotlib Plot Linestyle.ipynb\\n18-06-06 Every Matplotlib Plot Marker.ipynb\\n18-03-28 Creating Dummy Variables.ipynb\\n18-03-08 Removing Outliers.ipynb\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open a text file (which is a list of notebook names)\n",
    "file = open('Data/Notebooks/notebooks.txt','r', encoding=\"utf-8\")\n",
    "\n",
    "# Read file\n",
    "file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Import Data From Text FIle into a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:01.079073Z",
     "start_time": "2018-09-11T00:57:01.074811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17-08-01 Cross Validation and K-Folds.ipynb\\n',\n",
       " '18-07-03 Writing a File to AWS S3.ipynb\\n',\n",
       " '18-07-03 Reading a File from AWS S3.ipynb\\n',\n",
       " '18-07-03 Connecting to a Local Database.ipynb\\n',\n",
       " '18-07-03 Connecting to a Local Database with SHH.ipynb\\n',\n",
       " '17-11-07 Dimensional Pivot Table.ipynb\\n',\n",
       " '18-06-06 Every Matplotlib Plot Linestyle.ipynb\\n',\n",
       " '18-06-06 Every Matplotlib Plot Marker.ipynb\\n',\n",
       " '17-08-05 Histograms.ipynb\\n',\n",
       " '15-02-02 Barplots.ipynb\\n',\n",
       " '17-10-16 Wordclouds in Python.ipynb\\n',\n",
       " '17-12-04 Heatmaps.ipynb\\n',\n",
       " '18-07-07 Styling DataFrames.ipynb\\n',\n",
       " '18-07-07 Resampling Datetime.ipynb\\n',\n",
       " '18-07-24 Converting Notebook to Slides.ipynb\\n',\n",
       " '18-07-24 Label Encoding.ipynb\\n',\n",
       " '17-10-15 Plotting Residuals.ipynb\\n',\n",
       " '17-10-15 Correlation Matricesipynb\\n',\n",
       " '18-07-04 Select Dtypes.ipynb\\n',\n",
       " '18-03-28 Creating Dummy Variables.ipynb\\n',\n",
       " '17-10-09 Standardizations.ipynb\\n',\n",
       " '17-08-01 Random Grid Search.ipynb\\n',\n",
       " '17-08-01 Full Grid Search.ipynb\\n',\n",
       " '18-07-28 Notebook Snippets.ipynb\\n',\n",
       " '18-07-29 Iris Analysis.ipynb\\n',\n",
       " '18-07-29 Classification Models.ipynb\\n',\n",
       " '18-07-24 Binning Features.ipynb\\n',\n",
       " '17-08-01 Train-Test Split.ipynb\\n',\n",
       " '18-07-31 Fizzbuzz.ipynb\\n',\n",
       " '17-10-02 Handling Missing Data.ipynb\\n',\n",
       " '17-08-01 Recursive Feature Elimination.ipynb\\n']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open a text file (which is a list of notebook names)\n",
    "file = open('Data/notebooks.txt','r', encoding=\"utf-8\")\n",
    "\n",
    "# Read file lines instead\n",
    "file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Second method to got from a Text FIle into a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:01.085233Z",
     "start_time": "2018-09-11T00:57:01.080932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17-08-01 Cross Validation and K-Folds.ipynb',\n",
       " '18-07-03 Writing a File to AWS S3.ipynb',\n",
       " '18-07-03 Reading a File from AWS S3.ipynb',\n",
       " '18-07-03 Connecting to a Local Database.ipynb',\n",
       " '18-07-03 Connecting to a Local Database with SHH.ipynb',\n",
       " '17-11-07 Dimensional Pivot Table.ipynb',\n",
       " '18-06-06 Every Matplotlib Plot Linestyle.ipynb',\n",
       " '18-06-06 Every Matplotlib Plot Marker.ipynb',\n",
       " '17-08-05 Histograms.ipynb',\n",
       " '15-02-02 Barplots.ipynb',\n",
       " '17-10-16 Wordclouds in Python.ipynb',\n",
       " '17-12-04 Heatmaps.ipynb',\n",
       " '18-07-07 Styling DataFrames.ipynb',\n",
       " '18-07-07 Resampling Datetime.ipynb',\n",
       " '18-07-24 Converting Notebook to Slides.ipynb',\n",
       " '18-07-24 Label Encoding.ipynb',\n",
       " '17-10-15 Plotting Residuals.ipynb',\n",
       " '17-10-15 Correlation Matricesipynb',\n",
       " '18-07-04 Select Dtypes.ipynb',\n",
       " '18-03-28 Creating Dummy Variables.ipynb',\n",
       " '17-10-09 Standardizations.ipynb',\n",
       " '17-08-01 Random Grid Search.ipynb',\n",
       " '17-08-01 Full Grid Search.ipynb',\n",
       " '18-07-28 Notebook Snippets.ipynb',\n",
       " '18-07-29 Iris Analysis.ipynb',\n",
       " '18-07-29 Classification Models.ipynb',\n",
       " '18-07-24 Binning Features.ipynb',\n",
       " '17-08-01 Train-Test Split.ipynb',\n",
       " '18-07-31 Fizzbuzz.ipynb',\n",
       " '17-10-02 Handling Missing Data.ipynb',\n",
       " '17-08-01 Recursive Feature Elimination.ipynb']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open a text file (which is a list of notebook names) # Second Method\n",
    "with open('Data/notebooks.txt','r', encoding=\"utf-8\") as f:\n",
    "   \n",
    "    # Use \".read().splitlines()\" instead of  \".readlines()\"\n",
    "    mylist = f.read().splitlines()\n",
    "    \n",
    "# View list\n",
    "mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Copying Files to Another Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:01.091155Z",
     "start_time": "2018-09-11T00:57:01.086726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import mode modules\n",
    "from shutil import copyfile\n",
    "\n",
    "# generate a list of file paths with one file\n",
    "file_paths = ['/Users/Kavi/Documents/DataScience/README.md']\n",
    "\n",
    "# copy file to a different destination for every file in our list\n",
    "for filepaths in file_paths:\n",
    "    copyfile(filepaths, '/Users/Kavi/Documents/DataScience/Pipelines/Data/copy_README.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Writing a File to a Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:01.096556Z",
     "start_time": "2018-09-11T00:57:01.093298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Open text file\n",
    "with open('Data/sample_file.txt','w') as f2:\n",
    "    \n",
    "    # Write some text in the file\n",
    "    f2.write('sample text')\n",
    "    \n",
    "    # Close the file\n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Close you filse to save memory when iterating files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Appending Data to a File\n",
    "\n",
    "Here we are open a file appending some data to it and saving it again as another file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:01.101908Z",
     "start_time": "2018-09-11T00:57:01.098326Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Open an existing file as \"f1\"\n",
    "with open('Data/sample_file.txt','r') as f1:\n",
    "    # Create a new file as \"f2\n",
    "    with open('Data/sample_file2.txt','w') as f2: \n",
    "        \n",
    "        # Copy the text from the first file \n",
    "        f2.write(f1.read())\n",
    "        \n",
    "        # Write a new string info the file \n",
    "        f2.write(\"\\n You are the second version of the same file\")\n",
    "        \n",
    "        # Close the new file\n",
    "        f2.close()\n",
    "    \n",
    "    # Close the original file\n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Deleting Data in a Diretory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T00:57:01.106185Z",
     "start_time": "2018-09-11T00:57:01.103377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the text files from of data diretory\n",
    "os.remove(\"Data/sample_file2.txt\")\n",
    "os.remove(\"Data/sample_file.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kavi Sekhon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
